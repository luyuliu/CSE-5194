\documentclass[12pt]{article}
\begin{document}
\section*{CSE 5194 WEEK2 - Basic idea}
    \title{CSE 5194 WEEK2 - Basic idea}
    \paragraph{Feature}
    Feature is unsupervised. And many of deep learning is unsupervised. It is a good mix. 
    Feautre craft: the machine determine features for you.

    When the hidden layers shows a tripple pattern, it seems like a feature.

    input feature is dimension. Randomly.
    But featues can be infinite. machines learns that for you. Thousands.

    \subparagraph{Why machine learning is easy/hard}
    Machine does that for you, but the human brains can hardly reach dimension beyond 4.

    \subparagraph{the spot quiz}
    what is the green line: the model or the classifier.

    \paragraph{Histroy}
    \subparagraph{Perceptron}
    It is the simplest neural network. It is a linear. What is line? It is a Perceptron.
    \subparagraph{XOR question}
    someboday said Perceptron cannot solve NOR question. Basically it is inseparable.
    \subparagraph{Minsky}
    AI winter
    \subparagraph{Multi-layered perceptron}  
    MLP: a set of lines that define a region.
    Computability is a huge problem for them.

    \subparagraph{SVM}
    hyperspace. Limitation: it's a binary classifier.

    \paragraph{What is a deep neural network}
    The single node is a perceptron
    Multiple layers are a MLP.
    Any deep neural network is a MLP.

    
\end{document}